<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Responsible AI Policy - The National Research Institute for Democratized Learning">
    <title>Responsible AI Policy - NRIDL</title>
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Playfair+Display:wght@400;700;900&family=Montserrat:wght@100;200;300;400;500;600;700&display=swap" rel="stylesheet">
    
    <link rel="stylesheet" href="css/main.css">
    <link rel="stylesheet" href="css/navigation.css?v=1.2">
    <link rel="stylesheet" href="css/footer.css">
    <link rel="stylesheet" href="css/policy.css">
</head>
<body>
    <section class="policy-hero">
        <div class="container">
            <h1>Responsible AI Policy</h1>
            <div class="policy-meta">
                <span><strong>Updated Date:</strong> December 24, 2024</span>
            </div>
        </div>
    </section>

    <div class="policy-content">
        <section id="introduction" class="policy-section">
            <h2>1. Introduction</h2>
            <p>
                The National Research Institute for Democratized Learning ("NRIDL," "we," "us," or "our") is a nonprofit 
                organization dedicated to making AI and digital technologies accessible to all, thereby fostering equitable 
                education and bridging the digital divide. Our AI solutions and services ("AI Products") are designed to 
                empower communities, educators, small businesses, and learners with responsibly developed, transparent, and 
                mission-aligned tools. This Policy outlines our approach to developing, deploying, and using AI technologies 
                ethically and in line with our core values.
            </p>
        </section>

        <section id="scope" class="policy-section">
            <h2>2. Scope & Purpose</h2>
            <p>
                This AI Policy applies to all AI-driven features, tools, and initiatives provided or supported by NRIDL 
                through our websites, platforms, or partnerships (collectively, the "Services"). It governs how we design, 
                use, and manage AI to ensure that our solutions are developed and employed responsibly, transparently, and 
                for the public good.
            </p>
            <p>
                You may encounter additional offerings or integrations from third parties via our platforms or programs. 
                Those services are not covered by this Policy and remain subject to the terms and conditions of their 
                respective providers.
            </p>
        </section>

        <section id="principles" class="policy-section">
            <h2>3. Our Guiding Principles</h2>
            
            <h3>Democratized Access & Equity</h3>
            <p>
                We strive to ensure that our AI Products promote access for underserved groups, bridging socio-economic, 
                geographical, and cultural divides.
            </p>
            
            <h3>Transparency & Trust</h3>
            <p>
                We prioritize clear communication about when and how AI is used, ensuring that stakeholders—learners, 
                educators, community partners—understand the nature of AI-generated outputs and potential limitations.
            </p>
            
            <h3>Human-Centered Design & Ethics</h3>
            <p>
                We embed ethical considerations in every stage of AI development and deployment, placing human well-being, 
                dignity, and autonomy at the forefront.
            </p>
            
            <h3>Data Privacy & Security</h3>
            <p>
                We uphold strict policies to protect user data. We aim to use personal information only as necessary to 
                enhance AI capabilities responsibly, while maintaining confidentiality and security.
            </p>
            
            <h3>Accountability & Continuous Improvement</h3>
            <p>
                We regularly assess and refine our AI Products, striving to minimize unintended harm, reduce biases, and 
                respond proactively to community feedback.
            </p>
        </section>

        <section id="products-data" class="policy-section">
            <h2>4. AI Products and Your Data</h2>
            
            <h3>4.1 Types of AI Products</h3>
            <p>Our AI Products may include:</p>
            <ul>
                <li><strong>Generative AI Tools:</strong> Automated assistants that provide advice, draft text, develop lesson plans, or perform other generative tasks to support educators, small businesses, and community projects.</li>
                <li><strong>Analytics & Insights:</strong> Machine-learning models that analyze user-generated data to offer insights on learning outcomes, operational efficiency, or community engagement.</li>
                <li><strong>Personalized Learning Platforms:</strong> Adaptive educational technologies that tailor content to a learner's progress and needs.</li>
            </ul>
            
            <h3>4.2 Data Collection & Use</h3>
            <p><strong>User Input:</strong> When you interact with our AI Products—e.g., input text, prompts, questions, 
            or other content—we may use this data to generate outputs and improve model performance.</p>
            
            <p><strong>Aggregated & Anonymized Data:</strong> We may collect and aggregate user interactions for internal 
            research and to refine our AI Products. All personally identifiable information ("PII") is removed or anonymized 
            when used for training or analysis.</p>
            
            <p><strong>Training Models & Improving Services:</strong> NRIDL may use your inputs to enhance the accuracy 
            and relevance of our AI solutions. However, we do not use private or proprietary user content (e.g., uploaded 
            documents) to train third-party models unless explicitly authorized by the user.</p>
        </section>

        <section id="acceptable-use" class="policy-section">
            <h2>5. Acceptable Use</h2>
            
            <h3>5.1 Prohibited Uses</h3>
            <p>Our AI Products are intended for educational, humanitarian, and socially constructive purposes. 
            Accordingly, you shall not use them for:</p>
            <ul>
                <li><strong>Illegal or Harmful Purposes:</strong> Any activity that violates local, national, or international laws, or that promotes violence, terrorism, or abuse.</li>
                <li><strong>Harassment or Discrimination:</strong> Content that is threatening, harassing, defamatory, hateful, or otherwise discriminatory toward individuals or groups.</li>
                <li><strong>Misinformation or Manipulation:</strong> Creating deceptive materials, deepfakes, political propaganda, or fraudulent content.</li>
                <li><strong>Spam or Malicious Content:</strong> Disseminating large-scale spam, malicious code, or content-farming materials.</li>
                <li><strong>Privacy Violations:</strong> Submitting others' personal information without consent, or infringing upon data protection laws and regulations.</li>
                <li><strong>Intellectual Property Infringement:</strong> Violating copyright, trademark, or other intellectual property rights.</li>
                <li><strong>Prompt Injection or Exploits:</strong> Attempting to discover or manipulate the underlying source code or logic in unauthorized ways.</li>
            </ul>
            
            <h3>5.2 High-Risk Areas</h3>
            <p>
                Users must not deploy our AI Products in contexts deemed "high risk" under applicable AI legislation—such 
                as EU AI Act domains—unless explicitly approved in writing by NRIDL. This includes any use that may threaten 
                individual rights, health, or public safety.
            </p>
        </section>

        <section id="compliance" class="policy-section">
            <h2>6. Compliance & Enforcement</h2>
            
            <h3>6.1 Reporting Misuse</h3>
            <p>
                If you notice any misuse of our AI Products—such as generating harmful content, infringing on privacy, or 
                otherwise violating these standards—please contact us at <a href="mailto:support@nridl.org">support@nridl.org</a>. 
                We are committed to investigating and taking appropriate corrective action.
            </p>
            
            <h3>6.2 Consequences of Violation</h3>
            <p>
                Violations of this Policy or our other terms may lead to suspension or termination of access to our Services. 
                We reserve the right to take additional legal measures if warranted.
            </p>
        </section>

        <section id="third-party" class="policy-section">
            <h2>7. Use of Third-Party Service Providers</h2>
            <p>
                NRIDL may integrate third-party AI services to enhance features such as language translation, sentiment 
                analysis, or generative text. These third-party providers remain subject to their own terms of use and 
                policies, which we encourage you to review independently.
            </p>
            <p>
                We strive to work only with partners who share our values of data privacy, safety, and ethical development.
            </p>
        </section>

        <section id="security" class="policy-section">
            <h2>8. Security, Privacy, and Trust</h2>
            
            <h3>8.1 Security Measures</h3>
            <p>
                We employ technical and organizational safeguards to protect the confidentiality and integrity of data 
                processed by our AI Products. Although no system is entirely immune to security threats, we regularly 
                review and update our protocols to mitigate risks.
            </p>
            
            <h3>8.2 Ethical & Safety Reviews</h3>
            <p>
                Before releasing major updates or new AI features, we conduct ethical and safety reviews to identify and 
                address potential biases, harmful outcomes, or compliance issues. We encourage users to exercise caution 
                and judgment when relying on AI-generated content, especially in critical domains such as public health 
                or financial advice.
            </p>
            
            <h3>8.3 Transparency & Disclosure</h3>
            <p>
                Features that rely on third-party AI platforms will be clearly marked, and we will provide appropriate 
                disclosures indicating the nature of the AI being used. We encourage users to attribute any AI-generated 
                content to maintain transparency and trust.
            </p>
        </section>

        <section id="governance" class="policy-section">
            <h2>9. Responsible AI Development and Deployment</h2>
            
            <h3>Human Oversight and Accountability</h3>
            <p>
                NRIDL maintains an AI Ethics and Compliance Board (AIECB) comprising cross-functional members who oversee 
                ethical impact assessments, privacy reviews, and risk management for all AI projects.
            </p>
            
            <h3>Cybersecurity Measures</h3>
            <p>
                All data used for AI training and inference is encrypted both at rest and in transit. We implement strict 
                access controls, multifactor authentication, and regular security assessments.
            </p>
            
            <h3>Fairness and Equity</h3>
            <p>
                We actively test for and mitigate biases within AI models by employing diverse training datasets, applying 
                fairness metrics, and using debiasing techniques to minimize disparate impacts on marginalized communities.
            </p>
            
            <h3>Safety and Reliability</h3>
            <p>
                Prior to deployment, AI systems undergo rigorous testing, including adversarial testing and scenario-based 
                evaluations. Post-deployment monitoring ensures ongoing reliability and adherence to ethical standards.
            </p>
        </section>

        <section id="compliance-audits" class="policy-section">
            <h2>10. Compliance, Audits, and Certification</h2>
            <p>
                NRIDL conducts periodic internal audits to evaluate compliance with this policy and the effectiveness of 
                data protection, cybersecurity measures, and fairness mechanisms. We may also engage accredited third parties 
                for external audits or seek relevant certifications to enhance transparency and trust.
            </p>
        </section>

        <section id="updates" class="policy-section">
            <h2>11. Updates to this Policy</h2>
            <p>
                NRIDL reserves the right to update or modify this AI Policy at any time. Significant changes will be 
                announced on our website or via other relevant channels, and the updated version will be effective 
                immediately upon posting. Your continued use of our AI Products after such changes implies acceptance 
                of the revised terms.
            </p>
        </section>

        <section id="contact" class="policy-section">
            <div class="contact-box">
                <h3>12. Contact Us</h3>
                <p>If you have questions or concerns regarding this AI Policy or our AI practices, please reach out to us.</p>
                <p><strong>Email:</strong> <a href="mailto:support@nridl.org">support@nridl.org</a></p>
                <p style="margin-top: 1rem; font-size: 0.9375rem;">
                    We value your feedback and remain committed to improving our AI Products in alignment with our mission 
                    of democratizing learning, closing the digital divide, and fostering inclusive, equitable innovation.
                </p>
            </div>
        </section>
    </div>

    <script src="js/navigation.js?v=1.2"></script>
    <script src="js/footer.js"></script>
    <script src="js/common.js"></script>
</body>
</html>
